[TOC]

# CNN高级篇



## GoogleNet

![image-20201114103623868](images/image-20201114103623868.png)

### 减少代码冗余

函数、类===============定义Inception

### Concatenate：沿通道方向拼接

![image-20201114110420166](images/image-20201114110420166.png)

![image-20201114110436782](images/image-20201114110436782.png)

![image-20201114110525640](images/image-20201114110525640.png)

沿第一个维度，即Channel维度



### 信息融合

最终信息包含了各类源信息

![image-20201114104859832](images/image-20201114104859832.png)

注意x的来源，关于最初的3个5



### 1X1conv

降低运算量

![image-20201114105715494](images/image-20201114105715494.png)



### Inception模块

![image-20201114110630782](images/image-20201114110630782.png)

### Module实现

![image-20201114111012055](images/image-20201114111012055.png)

1408经过网络这层的输出，去掉全连接的那三行代码，实例化输出一次得到他的次数。



## ResidualNet（ResNet）

### 梯度消失

反向传播，链式求导，假设乘以一个小于1的数，最后趋近于0，那么梯度下降时，几乎不会下降。

解决：每层加锁，不适用深度学习，层数太多

![image-20201114113906820](images/image-20201114113906820.png)

跳连接

### module

![image-20201114113633003](images/image-20201114113633003.png)

逐步观测，查看张量大小是否是预期结果

